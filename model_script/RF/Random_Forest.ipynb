{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score : ```0.88```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read All Dataset CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_predict():\n",
    "    for folder_name in os.listdir(\"../../Competition_data\"):\n",
    "        if os.path.exists(f\"../../Competition_data/{folder_name}/y_predict.csv\") is False: continue\n",
    "        os.remove(f\"../../Competition_data/{folder_name}/y_predict.csv\")\n",
    "# use this function to remove all the y_predict.csv\n",
    "remove_all_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names=[]\n",
    "X_trains=[]\n",
    "y_trains=[]\n",
    "X_tests=[]\n",
    "for folder_name in os.listdir(\"../../Competition_data\"):\n",
    "    dataset_names.append(folder_name)\n",
    "    X_trains.append(pd.read_csv(f\"../../Competition_data/{folder_name}/X_train.csv\",header=0))\n",
    "    y_trains.append(pd.read_csv(f\"../../Competition_data/{folder_name}/y_train.csv\",header=0))\n",
    "    X_tests.append(pd.read_csv(f\"../../ompetition_data/{folder_name}/X_test.csv\",header=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n",
    "\n",
    "def get_number_of_datatype(X_data):\n",
    "    # Split the features in X_data into numeric_data and categorical_data.\n",
    "    numeric, categoric = [], []\n",
    "    for feature in X_data:\n",
    "        val = float(X_data.loc[i, feature])\n",
    "        if isinstance(val, float) and val.is_integer():\n",
    "                categoric.append(feature)\n",
    "        else:   numeric.append(feature)\n",
    "    return numeric, categoric\n",
    "\n",
    "dataset_datatype_cnt = []\n",
    "for i, _ in enumerate(dataset_names):\n",
    "    numeric_features, categoric_features = get_number_of_datatype(X_data = X_trains[i])\n",
    "    dataset_datatype_cnt.append((numeric_features, categoric_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split & build Model\n",
    "You can select an appropriate model and perform corresponding hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "models=[]\n",
    "for i in range(len(dataset_names)):\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numerical_transformer, dataset_datatype_cnt[i][0]),\n",
    "            (\"cat\", categorical_transformer, dataset_datatype_cnt[i][1]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Define the model\n",
    "    model = RandomForestClassifier(random_state = 42)\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", model)])\n",
    "    if TEST_MODEL:\n",
    "        tmp_X_train, tmp_X_test, tmp_y_train, tmp_y_test = train_test_split(X_trains[i], y_trains[i], test_size=0.2, random_state=42)\n",
    "        tmp_y_train = tmp_y_train.squeeze()\n",
    "        tmp_y_test = tmp_y_test.squeeze()\n",
    "        # Combine preprocessing steps\n",
    "        \n",
    "        pipeline.fit(tmp_X_train, tmp_y_train)\n",
    "        tmp_y_prob = pipeline.predict_proba(tmp_X_test)[:, 1]\n",
    "        auc = roc_auc_score(tmp_y_test, tmp_y_prob)\n",
    "    else:\n",
    "        y_trains[i] = y_trains[i].squeeze()\n",
    "        pipeline.fit(X_trains[i], y_trains[i])\n",
    "    models.append(pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicts=[]\n",
    "for i in range(len(dataset_names)):\n",
    "    y_predict_proba=models[i].predict_proba(X_tests[i])[:, 1]\n",
    "    df = pd.DataFrame(y_predict_proba, columns=['y_predict_proba'])\n",
    "    y_predicts.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,dataset_name in enumerate(dataset_names):\n",
    "    df = y_predicts[idx]\n",
    "    df.to_csv(f'../../Competition_data/{dataset_name}/y_predict.csv', index = False,header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
